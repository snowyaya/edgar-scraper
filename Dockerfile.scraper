# =============================================================================
# Dockerfile.scraper
# Python 3.12 one-shot scraper job
# =============================================================================
#
# This container runs the crawl pipeline and exits when done.
# To trigger a new crawl:
#   docker compose run scraper
#   docker compose run scraper python -m scraper.main --ciks 0000320193 --filing-types 10-K
#
# The scraper does NOT run Alembic — schema management is owned by the api
# container. The scraper assumes the schema already exists.

FROM python:3.12-slim AS deps

COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv

WORKDIR /app

COPY pyproject.toml uv.lock* ./
RUN uv sync --frozen --no-install-project

# =============================================================================
FROM python:3.12-slim AS final

COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv

WORKDIR /app

COPY --from=deps /app/.venv /app/.venv

ENV PATH="/app/.venv/bin:$PATH"
ENV PYTHONPATH="/app"
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

# Create output directory for JSONL export (mounted as volume in compose)
RUN mkdir -p /app/output

COPY scraper/ ./scraper/

RUN useradd --create-home --shell /bin/bash appuser && \
    chown -R appuser:appuser /app/output
USER appuser

# Default command — can be overridden via `docker compose run scraper <args>`
CMD ["python", "-m", "scraper.main"]
